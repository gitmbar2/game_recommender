{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Model\n",
    "\n",
    "### From playtime_distribution, we found 2-5, 6-25, 26+ as good initial cutoffs\n",
    "### Comparing to min / max normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "from src import EDA\n",
    "from src import ModelEvaluation\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO Maybe show playtime distribution picture here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelbarton/Code/gproject/src/EDA.py:20: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  return filtered_users[steam_df['game_name'].isin(usable_games['game_name'].values)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>game_name</th>\n",
       "      <th>purchase_action</th>\n",
       "      <th>playtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151603712</td>\n",
       "      <td>The Elder Scrolls V Skyrim</td>\n",
       "      <td>play</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151603712</td>\n",
       "      <td>Fallout 4</td>\n",
       "      <td>play</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid                   game_name purchase_action  playtime\n",
       "1  151603712  The Elder Scrolls V Skyrim            play     273.0\n",
       "3  151603712                   Fallout 4            play      87.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_df = EDA.load_without_cold_start(5)\n",
    "steam_df = steam_df[steam_df['purchase_action'] == 'play']\n",
    "steam_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some normalization needs to be done for played time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>game_name</th>\n",
       "      <th>purchase_action</th>\n",
       "      <th>playtime</th>\n",
       "      <th>playtime_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151603712</td>\n",
       "      <td>The Elder Scrolls V Skyrim</td>\n",
       "      <td>play</td>\n",
       "      <td>273.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151603712</td>\n",
       "      <td>Fallout 4</td>\n",
       "      <td>play</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid                   game_name purchase_action  playtime  \\\n",
       "1  151603712  The Elder Scrolls V Skyrim            play     273.0   \n",
       "3  151603712                   Fallout 4            play      87.0   \n",
       "\n",
       "   playtime_rank  \n",
       "1              3  \n",
       "3              3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_df[\"playtime_rank\"] = steam_df['playtime'].map(lambda value: EDA.rank_playtime(value))\n",
    "steam_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game names need to be changed to IDs for Spark ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting ALS must have numbers for itemCol and userCol\n",
    "steam_df = EDA.get_uids(steam_df, from_column='game_name', to_column='game_uid')\n",
    "steam_df['game_uid'].value_counts().size == steam_df['game_name'].value_counts().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-User vs Item-Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  2436\n",
      "Number of games:  3544\n"
     ]
    }
   ],
   "source": [
    "print('Number of users: ', steam_df['uid'].value_counts().size)\n",
    "print('Number of games: ', steam_df['game_name'].value_counts().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will use Co-clustering instead of relying only on user-user or item-item similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark ALS Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:  46128\n",
      "Test size:  11661\n"
     ]
    }
   ],
   "source": [
    "# Setup a SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "# Convert a Pandas DF to a Spark DF\n",
    "spark_df = spark.createDataFrame(steam_df)\n",
    "spark_df.count()\n",
    "train, test = spark_df.randomSplit([0.8, 0.2], seed=427471138)\n",
    "# can broadcast these\n",
    "\n",
    "print('Training size: ', train.count())\n",
    "print('Test size: ', test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "als_model = ALS(\n",
    "    itemCol='game_uid',\n",
    "    userCol='uid',\n",
    "    ratingCol='playtime_rank',\n",
    "    nonnegative=True,    \n",
    "    regParam=0.1,\n",
    "    coldStartStrategy=\"drop\", # Drops if user or item in test was not in train\n",
    "    rank=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fitted_als_model = als_model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----------+\n",
      "|game_uid|      uid|prediction|\n",
      "+--------+---------+----------+\n",
      "|       1|151603712| 1.3429985|\n",
      "+--------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "one_row_pandas_df = pd.DataFrame({'uid': [151603712], 'game_uid': [1]})\n",
    "one_row_spark_df = spark.createDataFrame(one_row_pandas_df)\n",
    "fitted_als_model.transform(one_row_spark_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = fitted_als_model.transform(test)\n",
    "evaluator = RegressionEvaluator() \\\n",
    "    .setMetricName(\"rmse\") \\\n",
    "    .setLabelCol(\"playtime_rank\") \\\n",
    "    .setPredictionCol(\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0051786784416223"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse\n",
    "# was 1.046 without restricting to 5+\n",
    "# was 1.005 with 5+, without min_max hours played\n",
    "# was 1.015 with 5+, 2+ users, without normalizing hours played\n",
    "# was 1.03 using 1-4 instead of 0-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelbarton/anaconda2/envs/py36/lib/python3.6/site-packages/pandas/core/groupby.py:4036: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "with_summaries_df = EDA.add_summaries(steam_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>game_name</th>\n",
       "      <th>purchase_action</th>\n",
       "      <th>playtime</th>\n",
       "      <th>playtime_rank</th>\n",
       "      <th>game_uid</th>\n",
       "      <th>playtime_mean</th>\n",
       "      <th>playtime_min</th>\n",
       "      <th>playtime_max</th>\n",
       "      <th>game_counts</th>\n",
       "      <th>min_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151603712</td>\n",
       "      <td>The Elder Scrolls V Skyrim</td>\n",
       "      <td>play</td>\n",
       "      <td>273.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>105.721530</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>562</td>\n",
       "      <td>0.412256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151603712</td>\n",
       "      <td>Fallout 4</td>\n",
       "      <td>play</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>65.274172</td>\n",
       "      <td>0.2</td>\n",
       "      <td>629.0</td>\n",
       "      <td>151</td>\n",
       "      <td>0.414122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>151603712</td>\n",
       "      <td>Spore</td>\n",
       "      <td>play</td>\n",
       "      <td>14.9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26.016667</td>\n",
       "      <td>0.1</td>\n",
       "      <td>417.0</td>\n",
       "      <td>54</td>\n",
       "      <td>0.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>151603712</td>\n",
       "      <td>Fallout New Vegas</td>\n",
       "      <td>play</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>52.247843</td>\n",
       "      <td>0.1</td>\n",
       "      <td>417.0</td>\n",
       "      <td>255</td>\n",
       "      <td>0.086352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         uid                   game_name purchase_action  playtime  \\\n",
       "1  151603712  The Elder Scrolls V Skyrim            play     273.0   \n",
       "3  151603712                   Fallout 4            play      87.0   \n",
       "5  151603712                       Spore            play      14.9   \n",
       "7  151603712           Fallout New Vegas            play      12.1   \n",
       "\n",
       "   playtime_rank  game_uid  playtime_mean  playtime_min  playtime_max  \\\n",
       "1              3         0     105.721530           0.1        1986.0   \n",
       "3              3         1      65.274172           0.2         629.0   \n",
       "5              2         2      26.016667           0.1         417.0   \n",
       "7              2         3      52.247843           0.1         417.0   \n",
       "\n",
       "   game_counts   min_max  \n",
       "1          562  0.412256  \n",
       "3          151  0.414122  \n",
       "5           54  0.106500  \n",
       "7          255  0.086352  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_summaries_df.head(4)\n",
    "# can drop some columns here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:  46128\n",
      "Test size:  11661\n"
     ]
    }
   ],
   "source": [
    "spark_df = spark.createDataFrame(with_summaries_df)\n",
    "spark_df.count()\n",
    "train, test = spark_df.randomSplit([0.8, 0.2], seed=427471138)\n",
    "print('Training size: ', train.count())\n",
    "print('Test size: ', test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7685464618302161"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_model = ALS(\n",
    "    itemCol='game_uid',\n",
    "    userCol='uid',\n",
    "    ratingCol='min_max',\n",
    "    nonnegative=True,    \n",
    "    regParam=0.1,\n",
    "    coldStartStrategy=\"drop\", # Drops if user or item in test was not in train\n",
    "    rank=10) \n",
    "\n",
    "fitted_als_model = als_model.fit(train)\n",
    "\n",
    "predictions = fitted_als_model.transform(test)\n",
    "evaluator = RegressionEvaluator() \\\n",
    "    .setMetricName(\"rmse\") \\\n",
    "    .setLabelCol(\"min_max\") \\\n",
    "    .setPredictionCol(\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_model = ALS(\n",
    "    itemCol='game_uid',\n",
    "    userCol='uid',\n",
    "    ratingCol='min_max',\n",
    "    nonnegative=True,    \n",
    "    regParam=0.1,\n",
    "    coldStartStrategy=\"drop\", # Drops if user or item in test was not in train\n",
    "    rank=10) \n",
    "\n",
    "fitted_als_model = als_model.fit(train)\n",
    "\n",
    "predictions = fitted_als_model.transform(test)\n",
    "# evaluator = RegressionEvaluator() \\\n",
    "#     .setMetricName(\"rmse\") \\\n",
    "#     .setLabelCol(\"min_max\") \\\n",
    "#     .setPredictionCol(\"prediction\")\n",
    "# rmse = evaluator.evaluate(predictions)\n",
    "# rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_count = predictions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.768546461830216"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify RMSE with rdd math\n",
    "predictions_rdd = predictions.rdd\n",
    "SSE = predictions_rdd.map(lambda r: (r['min_max'] - r['prediction'])**2) \\\n",
    "    .reduce(lambda total, x: total + x)\n",
    "math.sqrt(SSE / prediction_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  [[0.42567567567567566, 0.008724773302674294], [0.0006331785563528914, 0.000634816475212574]]\n"
     ]
    }
   ],
   "source": [
    "# For NDCG Calculation\n",
    "# fitted_als_model.recommendForAllUsers(n) may be an interesting alternative on train\n",
    "# predictions.groupBy('user_id') may be more efficient - df is more efficient than rdd\n",
    "\n",
    "test = (309404240,\n",
    "  [(0.0006331785563528914, 0.000634816475212574),\n",
    "   (0.42567567567567566, 0.008724773302674294)])\n",
    "\n",
    "def do_sort(arr):\n",
    "    actual_and_pred = np.array(arr)\n",
    "    indeces = np.argsort(actual_and_pred[:, 1])\n",
    "    return actual_and_pred[indeces[::-1]].tolist()\n",
    "    \n",
    "def sort_predictions_slice_relevance(arr, n):\n",
    "    actual_and_pred = np.array(arr)\n",
    "    indeces = np.argsort(actual_and_pred[:, 1])\n",
    "    return actual_and_pred[indeces[::-1]][:n].tolist()\n",
    "\n",
    "# lambda functions in rdds cant import modules\n",
    "def dcg_at_k(scores, k):\n",
    "    \"\"\"\n",
    "    Discounted cumulative gain\n",
    "    See http://fastml.com/evaluating-recommender-systems/\n",
    "    Args:\n",
    "        r: List - Relevance scores in rank order\n",
    "        k: Number of results to consider\n",
    "    Returns:\n",
    "        Float\n",
    "    \"\"\"\n",
    "    r = np.asfarray(scores)[:k]\n",
    "    if r.size:\n",
    "        # item 1 and 2 have same weights\n",
    "        return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        # use below for more emphasis on first rank\n",
    "        # return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "    return 0.\n",
    "\n",
    "def ndcg_at_k(scores, k, method=0):\n",
    "    \"\"\"\n",
    "    Normalized Discounted cumulative gain\n",
    "    See http://fastml.com/evaluating-recommender-systems/\n",
    "    Args:\n",
    "        r: List - Relevance scores in rank order\n",
    "        k: Number of results to consider\n",
    "    Returns:\n",
    "        Float from 0 to 1\n",
    "    \"\"\"\n",
    "    dcg_max = dcg_at_k(sorted(scores, reverse=True), k)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(scores, k) / dcg_max\n",
    "\n",
    "do_sort(test[1])\n",
    "x = sort_predictions_slice_relevance(test[1], 3)\n",
    "print('x: ', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use actual values for gain\n",
    "sampled = predictions_rdd.sample(False, 1, 1)\n",
    "formatted = sampled.map(lambda row: (row['uid'], [(row['min_max'], row['prediction'])])) \\\n",
    "    .reduceByKey(lambda total, val: total + val) \\\n",
    "    .map(lambda kv: (kv[0], sort_predictions_slice_relevance(kv[1], 10))) \\\n",
    "    .map(lambda kv: ndcg_at_k(np.array(kv[1])[:, 0], 10)) \\\n",
    "    .reduce(lambda total, gain: total + gain) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16524551374952542"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted / prediction_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
